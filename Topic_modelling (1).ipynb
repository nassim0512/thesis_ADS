{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing libraries"
      ],
      "metadata": {
        "id": "3Z5zUJ6dZzsw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4M9EqtSZF98"
      },
      "outputs": [],
      "source": [
        "!pip install gensim\n",
        "!pip install bertopic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading libraries"
      ],
      "metadata": {
        "id": "W4V1_2sMaEVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy  as np\n",
        "import string\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "#LDA\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
        "from gensim import corpora, models\n",
        "from gensim.models import Phrases\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# BERTopic\n",
        "from bertopic import BERTopic\n"
      ],
      "metadata": {
        "id": "7wFaXMBxaHSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading preprocessed data in\n",
        "df_clean = pd.read_pickle(\"data_randomized_complete_cleaned.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "gx184AlTaJ7z",
        "outputId": "49525751-b975-4ee9-c5b4-bd576dbee540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4db00f500fbf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading preprocessed data in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_randomized_complete_cleaned.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA topic modelling"
      ],
      "metadata": {
        "id": "m2eA8Bsgl7lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection"
      ],
      "metadata": {
        "id": "QVfN3qF7aaTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization tf_idf\n",
        "vectorizer = TfidfVectorizer(min_df=2, max_df=0.4, norm='l2')\n",
        "X = vectorizer.fit_transform(df_clean['clean_text'])\n",
        "tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "-N59_WvQaRFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copying the clean_text column of df_clean\n",
        "responses = df_clean['clean_text'].copy()\n",
        "responses = responses.reset_index()\n",
        "responses"
      ],
      "metadata": {
        "id": "_fq-VDTHlI0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Tokenization of the text\n",
        "responses['clean_text'] =  responses['clean_text'].apply(word_tokenize)\n",
        "responses['clean_text'].head()"
      ],
      "metadata": {
        "id": "hAIqTrU3aYwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA with maximum of 100 topics without gridsearch"
      ],
      "metadata": {
        "id": "_A3G2nwysM8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for calculating coherence scores\n",
        "def coherence_values(dictionary, corpus, texts, limit, start, step):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        print('Calculating for',num_topics,'topics')\n",
        "        model = LdaModel(corpus=corpus, num_topics=num_topics, alpha=0.01, eta=0.1)\n",
        "        model_list.append(model)\n",
        "\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "    return model_list, coherence_values\n",
        "\n",
        "    #create dictionary\n",
        "id2word = corpora.Dictionary(responses['clean_text'])\n",
        "\n",
        "\n",
        "#Filter out words that occur in less than 20 documents or more than 50% of the documents. You can experiment with different values here.\n",
        "id2word.filter_extremes(no_below=10, no_above=0.4)\n",
        "\n",
        "#Create corpus\n",
        "corpus = [id2word.doc2bow(doc) for doc in responses['clean_text']]\n",
        "\n",
        "start = 1\n",
        "limit = 100\n",
        "step = 2\n",
        "\n",
        "model_list, coherence_values = coherence_values(dictionary=id2word, corpus=corpus, texts=responses['clean_text'], start=start, limit=limit, step=step)"
      ],
      "metadata": {
        "id": "wdyJZ9K1q37B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the coherence values\n",
        "x = range(start, limit, step)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZSw-Jb0rr57o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the topics and their coherence values\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "metadata": {
        "id": "El1LUu0Ir6sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the number of topics and coherence values\n",
        "topics_coherence = list(zip(x, coherence_values))\n",
        "\n",
        "# Sort the list by coherence values in descending order\n",
        "topics_coherence.sort(key=lambda pair: pair[1], reverse=True)\n",
        "\n",
        "# Get the top three coherence values and their corresponding number of topics\n",
        "top_three = topics_coherence[:6]\n",
        "\n",
        "# Print the top three results\n",
        "for m, cv in top_three:\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "metadata": {
        "id": "ghcHkBDBr9gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate model output\n",
        "lda_model = LdaModel(corpus=corpus, num_topics=7,id2word=id2word)\n",
        "lda_model.print_topics()"
      ],
      "metadata": {
        "id": "7Z5n1hRMsDGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate model output\n",
        "lda_model = LdaModel(corpus=corpus, num_topics=11,id2word=id2word)\n",
        "lda_model.print_topics()"
      ],
      "metadata": {
        "id": "oSTICljisDoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking subset for gridsearch, due to computational constraints\n",
        "sampled_responses_fixed = responses.sample(n=50000, random_state=42)"
      ],
      "metadata": {
        "id": "4_K9qxTmlFiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for calculating coherence scores and performing grid search\n",
        "def coherence_values(dictionary, corpus, texts, start, limit, step, alpha_values, eta_values):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    param_configurations = []\n",
        "\n",
        "    # Grid search over number of topics, alpha, and eta\n",
        "    for num_topics in range(start, limit, step):\n",
        "        for alpha in alpha_values:\n",
        "            for eta in eta_values:\n",
        "                print(f'Calculating for {num_topics} topics, alpha={alpha}, eta={eta}')\n",
        "                # Build LDA model with specified parameters\n",
        "                model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary,\n",
        "                                 alpha=alpha, eta=eta, random_state=100)\n",
        "                model_list.append(model)\n",
        "\n",
        "                # Calculate Coherence\n",
        "                coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "                coherence_score = coherencemodel.get_coherence()\n",
        "                coherence_values.append(coherence_score)\n",
        "                param_configurations.append((num_topics, alpha, eta, coherence_score))\n",
        "\n",
        "    return model_list, coherence_values, param_configurations\n",
        "\n",
        "id2word = corpora.Dictionary(responses['clean_text'])\n",
        "\n",
        "#Create corpus\n",
        "corpus = [id2word.doc2bow(doc) for doc in responses['clean_text']]\n",
        "\n",
        "# Specified alpha and eta values for the grid search\n",
        "alpha_values = [0.01, 0.1, 0.5, 'asymmetric']\n",
        "eta_values = [0.01, 0.5, 0.1, 'auto']\n",
        "\n",
        "# Defined the range of topic numbers\n",
        "start, limit, step = 1, 20, 1\n",
        "\n",
        "# Call the coherence_values function with alpha and eta grid search\n",
        "model_list, coherence_scores, configurations = coherence_values(\n",
        "    dictionary=id2word, corpus=corpus, texts=responses['clean_text'],\n",
        "    start=start, limit=limit, step=step, alpha_values=alpha_values, eta_values=eta_values\n",
        ")\n",
        "\n",
        "# Print out the coherence scores and parameter configurations\n",
        "for config in configurations:\n",
        "    print(\"Num Topics:\", config[0], \"Alpha:\", config[1], \"Eta:\", config[2], \"Coherence:\", round(config[3], 4))\n"
      ],
      "metadata": {
        "id": "fl0h3QF3lPEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the topics for the best coherence value\n",
        "lda_model = LdaModel(corpus=corpus, num_topics=3,id2word=id2word, alpha= 0.1, eta=0.01)\n",
        "lda_model.print_topics()"
      ],
      "metadata": {
        "id": "C42kMCD7liQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERTopic modelling"
      ],
      "metadata": {
        "id": "fkri-C7tl_OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting into list\n",
        "documents = df_clean['clean_text'].tolist()\n",
        "documents"
      ],
      "metadata": {
        "id": "jw_f8uAMmByZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a BERTopic model.\n",
        "topic_model = BERTopic(embedding_model='paraphrase-Multilingual-MiniLM-L12-v2', language='Dutch', min_topic_size=40, nr_topics='auto')\n",
        "\n",
        "\n",
        "#'paraphrase-MiniLM-L6-v2'\n",
        "# Fit the model to your documents\n",
        "topics, probabilities = topic_model.fit_transform(documents)\n",
        "\n",
        "# Get an overview of the topics\n",
        "topic_info = topic_model.get_topic_info()"
      ],
      "metadata": {
        "id": "lZ0J-gNJmVhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the topics found by the model\n",
        "print(topic_model.get_topic_info())\n",
        "\n",
        "# Retrieve words for each topic\n",
        "for i in range(len(topic_model.get_topics())):\n",
        "    print(f\"Topic {i}'s top words: {topic_model.get_topic(i)}\")"
      ],
      "metadata": {
        "id": "oHgqqbhzmpGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the topics for better understanding and to make further decisions\n",
        "topic_model.visualize_topics()"
      ],
      "metadata": {
        "id": "bnaCzU4UmqAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After visualization decided to take 49 topics, because a lot of topics were in the same area\n",
        "topic_model.reduce_topics(documents, nr_topics=49)\n",
        "\n",
        "# Examine the new topic information\n",
        "bertopic_info_df = topic_model.get_topic_info()\n",
        "bertopic_info_df"
      ],
      "metadata": {
        "id": "qkCync_hms-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting words from topics\n",
        "topics = topic_model.get_topics()\n",
        "words_per_topic = {topic: [word for word, _ in topics[topic]] for topic in topics}\n",
        "\n",
        "# Create a dictionary and corpus\n",
        "# Exclude -1 because it represents outlier class\n",
        "dictionary = corpora.Dictionary([words_per_topic[topic] for topic in topics if topic != -1])\n",
        "\n",
        "# Convert words to BOW format\n",
        "corpus = [dictionary.doc2bow(words) for words in words_per_topic.values() if words]"
      ],
      "metadata": {
        "id": "EtR_6wBhnD8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the top words for each topic\n",
        "texts = [[word for word, _ in topic_model.get_topic(topic)] for topic in topics if topic != -1]\n",
        "\n",
        "# Retrieving coherence values\n",
        "coherence_model = CoherenceModel(topics=texts, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence_values = coherence_model.get_coherence()"
      ],
      "metadata": {
        "id": "t837XhwlnO1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the coherence value of the BERTopic model\n",
        "coherence_values"
      ],
      "metadata": {
        "id": "yobN9mAZnkLQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}